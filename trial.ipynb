{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "import sys\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import wandb\n",
    "import regex as re\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import wandb\n",
    "import lightning as pl\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>native</th>\n",
       "      <th>latin</th>\n",
       "      <th>n_annot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ஃபியட்</td>\n",
       "      <td>fiat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ஃபியட்</td>\n",
       "      <td>phiyat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ஃபியட்</td>\n",
       "      <td>piyat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ஃபிரான்ஸ்</td>\n",
       "      <td>firaans</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ஃபிரான்ஸ்</td>\n",
       "      <td>france</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      native    latin  n_annot\n",
       "0     ஃபியட்     fiat        2\n",
       "1     ஃபியட்   phiyat        1\n",
       "2     ஃபியட்    piyat        1\n",
       "3  ஃபிரான்ஸ்  firaans        1\n",
       "4  ஃபிரான்ஸ்   france        2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = \"/home/user/Documents/Courses/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\"\n",
    "valid_path = \"/home/user/Documents/Courses/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.dev.tsv\"\n",
    "test_path = \"/home/user/Documents/Courses/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.test.tsv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path, sep=\"\\t\", header=None, names=[\"native\", \"latin\", 'n_annot'], encoding='utf-8')\n",
    "valid_df = pd.read_csv(valid_path, sep=\"\\t\", header=None, names=[\"native\", \"latin\", 'n_annot'], encoding='utf-8')\n",
    "test_df = pd.read_csv(test_path, sep=\"\\t\", header=None, names=[\"native\", \"latin\", 'n_annot'], encoding='utf-8')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[~train_df['latin'].isna()]\n",
    "valid_df = valid_df[~valid_df['latin'].isna()]\n",
    "test_df = test_df[~test_df['latin'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NativeTokenizer():\n",
    "    def __init__(self, train_path, valid_path, test_path, special_tokens={'START': '<start>','END':'<end>', 'PAD':'<pad>'}):\n",
    "        \n",
    "        self.train_df = pd.read_csv(train_path, sep=\"\\t\", header=None, names=[\"native\", \"latin\", 'n_annot'], encoding='utf-8')\n",
    "        self.valid_df = pd.read_csv(valid_path, sep=\"\\t\", header=None, names=[\"native\", \"latin\", 'n_annot'], encoding='utf-8')\n",
    "        self.test_df = pd.read_csv(test_path, sep=\"\\t\", header=None, names=[\"native\", \"latin\", 'n_annot'], encoding='utf-8')\n",
    "        self.special_tokens = special_tokens\n",
    "        # Build vocabulary\n",
    "        self._build_vocab(add_special_tokens=True)\n",
    "        \n",
    "        # Id to token mapping\n",
    "        self.id_to_latin = {i: char for i, char in enumerate(self.latin_vocab)}\n",
    "        self.id_to_native = {i: char for i, char in enumerate(self.native_vocab)}\n",
    "\n",
    "        self.latin_vocab_size = len(self.latin_vocab)\n",
    "        self.nat_vocab_size = len(self.native_vocab)\n",
    "\n",
    "    # Build vocabulary\n",
    "    def _build_vocab(self, add_special_tokens=True):\n",
    "        self.nat_set = set()\n",
    "        self.latin_set = set()\n",
    "        for lat, nat in zip(self.train_df['latin'], self.train_df['native']):\n",
    "            nat_chars = re.findall(r'\\X' , nat)\n",
    "            try:\n",
    "                lat_chars = list(lat)\n",
    "            except:\n",
    "                print(f\"Invalid latin string: {lat}, skipping....\")\n",
    "            \n",
    "            for char in nat_chars:\n",
    "                self.nat_set.add(char)\n",
    "            for char in lat_chars:\n",
    "               self.latin_set.add(char.lower())\n",
    "            \n",
    "        self.nat_set = sorted(list(self.nat_set))\n",
    "        self.latin_set = sorted(list(self.latin_set))\n",
    "        \n",
    "        if add_special_tokens:\n",
    "            self.nat_set = list(self.special_tokens.values()) + self.nat_set\n",
    "            self.latin_set = [self.special_tokens['PAD']] + self.latin_set   \n",
    "\n",
    "        self.latin_vocab = {char: i for i, char in enumerate(self.latin_set)}\n",
    "        self.native_vocab = {char: i for i, char in enumerate(self.nat_set)}\n",
    "\n",
    "    def tokenize(self, text, lang='latin'):\n",
    "        if type(text) != str:\n",
    "            print(\"Invalid text:\", text)\n",
    "            print(\"Language must be a string, but got\", type(text))\n",
    "        if lang == 'latin':\n",
    "            return [self.latin_vocab[char] for char in text]\n",
    "        elif lang == 'native':\n",
    "            return [self.native_vocab['<start>']] + [self.native_vocab[char] for char in re.findall('\\X', text)] + [self.native_vocab['<end>']]\n",
    "        else:\n",
    "            raise ValueError(\"Language must be either 'latin' or 'native'.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid latin string: nan, skipping....\n",
      "Invalid latin string: nan, skipping....\n",
      "Invalid latin string: nan, skipping....\n",
      "Latin vocab size: 27\n",
      "Native vocab size: 253\n"
     ]
    }
   ],
   "source": [
    "tokenizer = NativeTokenizer(train_path, valid_path, test_path)\n",
    "print(f\"Latin vocab size: {tokenizer.latin_vocab_size}\")\n",
    "print(f\"Native vocab size: {tokenizer.nat_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatNatDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.df.iloc[idx]\n",
    "        latin_word = entry['latin']\n",
    "        native_word = entry['native']\n",
    "               \n",
    "        # Tokenize and convert to IDs\n",
    "        #latin_ids = [self.tokenizer.latin_vocab[i] for i in latin_word]\n",
    "        #native_ids = [self.tokenizer.native_vocab[i] for i in re.findall(r'\\X' , native_word)]\n",
    "        latin_ids = self.tokenizer.tokenize(latin_word, lang='latin')\n",
    "        native_ids = self.tokenizer.tokenize(native_word, lang='native')\n",
    "\n",
    "\n",
    "        return (torch.tensor(latin_ids),\n",
    "            torch.tensor(native_ids))\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        x,y = zip(*batch)\n",
    "        x_len = [len(seq) for seq in x]\n",
    "        y_len = [len(seq) for seq in y]\n",
    "\n",
    "        padded_x = pad_sequence(x, batch_first=True, padding_value=self.tokenizer.latin_vocab['<pad>'])\n",
    "        padded_y = pad_sequence(y, batch_first=True, padding_value=self.tokenizer.native_vocab['<pad>'])\n",
    "        \n",
    "        x_len, perm_idx = torch.tensor(x_len).sort(0, descending=True)\n",
    "        padded_x = padded_x[perm_idx]\n",
    "\n",
    "        y_len = torch.tensor(y_len).sort(0, descending=True)\n",
    "        padded_y = padded_y[perm_idx]\n",
    "\n",
    "        return padded_x, x_len, padded_y, y_len\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LatNatDataset(train_df, tokenizer)\n",
    "valid_dataset = LatNatDataset(valid_df, tokenizer)\n",
    "test_dataset = LatNatDataset(test_df, tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=train_dataset.collate_fn, num_workers=2)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=False, collate_fn=valid_dataset.collate_fn , num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=test_dataset.collate_fn, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, cell, num_layers, dropout, activation='tanh'):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=input_size, embedding_dim=embedding_size, )\n",
    "        if cell =='rnn':\n",
    "            self.rnn = torch.nn.RNN(input_size=embedding_size, hidden_size=hidden_size, batch_first=True, num_layers=num_layers, dropout=dropout, nonlinearity=activation)\n",
    "        elif cell == 'LSTM':\n",
    "            self.rnn = torch.nn.GRU(input_size=embedding_size, hidden_size=hidden_size, batch_first=True, num_layers=num_layers,dropout=dropout)\n",
    "        elif cell == 'GRU':\n",
    "            self.rnn = torch.nn.LSTM(input_size=embedding_size, hidden_size=hidden_size, batch_first=True, num_layers=num_layers, dropout=dropout)\n",
    "    \n",
    "    def forward(self, seq, seq_len):\n",
    "        embedding = self.embedding(input=seq)\n",
    "        packed = pack_padded_sequence(input=embedding, lengths=seq_len, batch_first=True, enforce_sorted=True)\n",
    "        output, hidden = self.rnn(packed)\n",
    "        output, _ = pad_packed_sequence(output, batch_first=True)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, output_size, embedding_size, hidden_size, cell, num_layers, dropout, activation='tanh'):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=output_size, embedding_dim=embedding_size)\n",
    "        if cell == 'rnn':\n",
    "            self.rnn = torch.nn.RNN(input_size=embedding_size, hidden_size=hidden_size, batch_first=True, num_layers=num_layers, nonlinearity=activation, dropout=dropout)\n",
    "        elif cell == 'LSTM':\n",
    "            self.rnn = torch.nn.GRU(input_size=embedding_size, hidden_size=hidden_size, batch_first=True, num_layers=num_layers, dropout=dropout)\n",
    "        elif cell == 'GRU':\n",
    "            self.rnn = torch.nn.GRU(input_size=embedding_size, hidden_size=hidden_size, batch_first=True, num_layers=num_layers, dropout=dropout)\n",
    "        self.out = torch.nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=2)  \n",
    "\n",
    "    def forward(self, input_step, hidden):\n",
    "        # input_step: (batch_size, 1) [a single timestep]\n",
    "        embedded = self.embedding(input_step)  # (batch_size, 1, hidden_size)\n",
    "\n",
    "        rnn_output, hidden = self.rnn(embedded, hidden)  # output: (batch_size, 1, hidden_size)\n",
    "        output = self.out(rnn_output)  # (batch_size, 1, output_size)\n",
    "        return output, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "def train(input_tensor, input_lengths, target_tensor, target_lengths, encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, criterion, max_target_len, teacher_forcing_ratio=0.5):\n",
    "    special_tokens = {key: val for key, val in tokenizer.native_vocab.items() if key in ['<start>', '<end>', '<pad>']}\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    batch_size = input_tensor.size(0)\n",
    "    loss = 0\n",
    "\n",
    "    _, encoder_hidden = encoder(input_tensor, input_lengths)\n",
    "\n",
    "    # Prepare decoder input and hidden state\n",
    "\n",
    "    decoder_input = target_tensor[:, :-1].detach().clone()\n",
    "    decoder_target = target_tensor[:, 1:].detach().clone()\n",
    "\n",
    "    #decoder_input = torch.tensor(([SOS_token]*batch_size)).unsqueeze(1)\n",
    "    \n",
    "    #print(\"decoder input\", decoder_input.shape)\n",
    "\n",
    "    \n",
    "    decoder_hidden = encoder_hidden # directly use last hidden state from encoder\n",
    "    # Feed the target as the next input\n",
    "    for i in range(target_tensor.shape[1]-1):\n",
    "\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input[:, i].unsqueeze(1), decoder_hidden)\n",
    "        #decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "        #decoder_input = decoder_output.argmax(dim=2)\n",
    "        #print(\"decoder output: \", decoder_output.shape)\n",
    "        loss += criterion(decoder_output.squeeze(1), decoder_target[:, i])\n",
    "        # Append the new column\n",
    "        if i == 0:\n",
    "            preds = decoder_output.argmax(dim=2).cpu().numpy()\n",
    "        else:\n",
    "            preds = np.hstack((preds, decoder_output.argmax(dim=2).cpu().numpy()))\n",
    "\n",
    "    mask = ~torch.isin(decoder_target[:,:-1], torch.tensor(list(special_tokens.values())))\n",
    "    masked_preds = torch.tensor(preds[:, :-1]).masked_fill(~mask, -1)\n",
    "    masked_targets = decoder_target[:, :-1].masked_fill(~mask, -1)\n",
    "\n",
    "    exact_matches = (masked_preds == masked_targets).all(dim=1)\n",
    "    accuracy = exact_matches.float().mean()\n",
    "    words = \"\".join([tokenizer.id_to_native[i] for i in preds[0]])\n",
    "    #print(decoder_target[0:1, :-1].tolist())\n",
    "    truth = \"\".join([tokenizer.id_to_native[i] for i in decoder_target[0:1, :-1].tolist()[0]])\n",
    "    #print(f\"Pred: {words}, Truth: {truth}\")\n",
    "    \n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / max_target_len, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(decoder, encoder_outputs, beam_width, max_len, start_token, end_token):\n",
    "    # Each beam stores (sequence, score)\n",
    "    best_seqs = []\n",
    "    for i in range(encoder_outputs.size(0)):\n",
    "        beams = [(torch.tensor([start_token]), 0.0)]  # Start with start token\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            all_candidates = []\n",
    "            for seq, score in beams:\n",
    "                if seq[-1].item() == end_token:\n",
    "                    # Already ended; keep as is\n",
    "                    all_candidates.append((seq, score))\n",
    "                    continue\n",
    "                \n",
    "                # Get decoder output probabilities for last token\n",
    "                input_token = seq[-1].unsqueeze(0).unsqueeze(0)  # shape (1,1)\n",
    "                output_logits, hidden = decoder(input_token)\n",
    "                log_probs = torch.log_softmax(output_logits, dim=-1).squeeze(0).squeeze(0)\n",
    "\n",
    "                # Get top-k tokens and their log probabilities\n",
    "                topk_log_probs, topk_tokens = torch.topk(log_probs, beam_width)\n",
    "\n",
    "                for k in range(beam_width):\n",
    "                    next_token = topk_tokens[k].unsqueeze(0)\n",
    "                    new_seq = torch.cat([seq, next_token])\n",
    "                    new_score = score + topk_log_probs[k].item()\n",
    "                    all_candidates.append((new_seq, new_score))\n",
    "\n",
    "            # Select top beam_width sequences\n",
    "            beams = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n",
    "\n",
    "            # Optional: break early if all beams ended with end_token\n",
    "            if all(seq[-1].item() == end_token for seq, _ in beams):\n",
    "                break\n",
    "\n",
    "        # Return best sequence (highest score)\n",
    "        best_seq = beams[0][0]\n",
    "        best_seqs.append(best_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = tokenizer.latin_vocab_size\n",
    "OUTPUT_SIZE = tokenizer.nat_vocab_size\n",
    "EMBEDDING_SIZE = 128\n",
    "HIDDEN_SIZE = 256\n",
    "MAX_TARGET_LEN = 28  # Set this to the maximum length of your target sequences\n",
    "SOS_token = tokenizer.native_vocab['<start>']\n",
    "PAD_TOKEN = tokenizer.native_vocab['<pad>']\n",
    "EOS_token = tokenizer.native_vocab['<end>']\n",
    "encoder = Encoder(input_size=INPUT_SIZE, embedding_size= EMBEDDING_SIZE,hidden_size=HIDDEN_SIZE, cell='rnn', num_layers=2, dropout=0.1)\n",
    "decoder = Decoder(output_size=OUTPUT_SIZE, embedding_size= EMBEDDING_SIZE,hidden_size=HIDDEN_SIZE, cell='rnn', num_layers=2, dropout=0.1)\n",
    "\n",
    "# Optimizers and loss\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.native_vocab['<pad>'])  # Assume PAD token is 0\n",
    "\n",
    "\n",
    "\n",
    "def train_iters(encoder, decoder, n_epochs, training_data, encoder_optimizer, decoder_optimizer, \n",
    "                criterion, max_target_len, batch_size=32, teacher_forcing_ratio=0.5, print_every=1):\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        print(f\"Epoch {epoch}/{n_epochs}\")\n",
    "        total_loss = 0\n",
    "        accuracy = []\n",
    "        # Assuming training_data is a list of (input_tensor, input_length, target_tensor, target_length)\n",
    "        for batch in training_data:\n",
    "            input_tensor, input_lengths, target_tensor, target_lengths = batch\n",
    "            loss, acc = train(input_tensor, input_lengths, target_tensor, target_lengths,\n",
    "                         encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "                         criterion, max_target_len=max_target_len,\n",
    "                         teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "            total_loss += loss\n",
    "\n",
    "            accuracy.append(acc)\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            avg_loss = total_loss / len(training_data)\n",
    "            print(f\"Epoch {epoch}/{n_epochs}, Loss: {avg_loss:.4f}\")\n",
    "            print(f\"Epoch {epoch}/{n_epochs}, avg acc: {np.mean(accuracy):.4f}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10, Loss: 0.7298\n",
      "Epoch 1/10, avg acc: 0.0008\n",
      "Epoch 2/10\n",
      "Epoch 2/10, Loss: 0.5653\n",
      "Epoch 2/10, avg acc: 0.0019\n",
      "Epoch 3/10\n",
      "Epoch 3/10, Loss: 0.4895\n",
      "Epoch 3/10, avg acc: 0.0043\n",
      "Epoch 4/10\n",
      "Epoch 4/10, Loss: 0.4533\n",
      "Epoch 4/10, avg acc: 0.0073\n",
      "Epoch 5/10\n",
      "Epoch 5/10, Loss: 0.4381\n",
      "Epoch 5/10, avg acc: 0.0089\n",
      "Epoch 6/10\n",
      "Epoch 6/10, Loss: 0.4182\n",
      "Epoch 6/10, avg acc: 0.0110\n",
      "Epoch 7/10\n",
      "Epoch 7/10, Loss: 0.3916\n",
      "Epoch 7/10, avg acc: 0.0159\n",
      "Epoch 8/10\n",
      "Epoch 8/10, Loss: 0.3701\n",
      "Epoch 8/10, avg acc: 0.0228\n",
      "Epoch 9/10\n",
      "Epoch 9/10, Loss: 0.3566\n",
      "Epoch 9/10, avg acc: 0.0269\n",
      "Epoch 10/10\n",
      "Epoch 10/10, Loss: 0.3522\n",
      "Epoch 10/10, avg acc: 0.0295\n"
     ]
    }
   ],
   "source": [
    "train_iters(\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    n_epochs=10,\n",
    "    training_data=train_dataloader,\n",
    "    encoder_optimizer=encoder_optimizer,\n",
    "    decoder_optimizer=decoder_optimizer,\n",
    "    criterion=criterion,\n",
    "    max_target_len=MAX_TARGET_LEN,\n",
    "    batch_size=32,\n",
    "    teacher_forcing_ratio=1,\n",
    "    \n",
    "    print_every=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_light(pl.LightningModule):\n",
    "    def __init__(self, input_sizes, embedding_size, hidden_size, cell, layers, dropout, activation, beam_size, optim, special_tokens, lr):\n",
    "        super().__init__()\n",
    "        self.optim = optim\n",
    "        self.save_hyperparameters()\n",
    "        self.beam_size = beam_size\n",
    "        if layers == 1:\n",
    "            print(\"Dropout is not applied for 1 layer\")\n",
    "            dropout = 0 \n",
    "        self.encoder = Encoder(input_sizes[0], embedding_size, hidden_size, cell=cell, num_layers=layers, dropout=dropout, activation=activation)\n",
    "        self.decoder = Decoder(input_sizes[1], embedding_size, hidden_size, cell=cell, num_layers=layers, dropout=dropout, activation=activation)\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss(ignore_index=special_tokens['<pad>'])\n",
    "        self.special_tokens = special_tokens   \n",
    "        self.beam_size = beam_size \n",
    "    def forward(self, input_tensor=[], input_lengths=[], decoder_input=[], decoder_hidden= [], encoder=False):\n",
    "        if encoder:\n",
    "            _, decoder_hidden = self.encoder(input_tensor, input_lengths)\n",
    "            print(\"decoder input: \", decoder_input.shape)\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "        else:\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "        return decoder_output, decoder_hidden\n",
    "\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_tensor, input_lengths, target_tensor, target_lengths = batch\n",
    "        decoder_input = target_tensor[:, :-1].detach().clone()\n",
    "        decoder_target = target_tensor[:, 1:].detach().clone()\n",
    "        loss = 0\n",
    "        _, decoder_hidden = self.encoder(input_tensor, input_lengths)\n",
    "\n",
    "\n",
    "        for i in range(target_tensor.shape[1]-1):\n",
    "            if i ==0:\n",
    "                # first step\n",
    "                decoder_output, decoder_hidden = self.decoder(decoder_input[:, i].unsqueeze(1), decoder_hidden)\n",
    "                #decoder_output, decoder_hidden = self(input_tensor = input_tensor, input_lengths=input_lengths, decoder_input = decoder_input[:, i].unsqueeze(1), encoder=True)\n",
    "   \n",
    "                loss += self.loss_fn(decoder_output.squeeze(1), decoder_target[:, i])\n",
    "                preds = decoder_output.argmax(dim=2).cpu().numpy()\n",
    "            else:\n",
    "                # rest of the steps\n",
    "                decoder_output, decoder_hidden = self.decoder(decoder_input[:, i].unsqueeze(1), decoder_hidden)\n",
    "                #decoder_output, decoder_hidden = self(decoder_input=decoder_input[:, i].unsqueeze(1), decoder_hidden=decoder_hidden)\n",
    " \n",
    "                loss += self.loss_fn(decoder_output.squeeze(1), decoder_target[:, i])\n",
    "                preds = np.hstack((preds, decoder_output.argmax(dim=2).cpu().numpy()))\n",
    "        \n",
    "        # masking pad tokens and end tokens for accuracy calculation\n",
    "        \n",
    "        mask = ~torch.isin(decoder_target[:,:-1], torch.tensor(list(self.special_tokens.values())))\n",
    "\n",
    "        masked_preds = torch.tensor(preds[:, :-1]).masked_fill(~mask, self.special_tokens['<pad>'])\n",
    "        masked_targets = decoder_target[:, :-1].masked_fill(~mask, self.special_tokens['<pad>'])\n",
    "        exact_matches = (masked_preds == masked_targets).all(dim=1)\n",
    "        accuracy = exact_matches.float().mean()\n",
    " \n",
    "        self.log(\"train loss\", loss, on_step = False, on_epoch = True)\n",
    "        self.log(\"train accuracy\", accuracy, on_step = False, on_epoch = True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_tensor, input_lengths, target_tensor, target_lengths = batch\n",
    "        decoder_input = target_tensor[:, :-1].detach().clone()\n",
    "        decoder_target_batch = target_tensor[:, 1:].detach().clone()\n",
    "        loss = 0\n",
    "        _, decoder_hidden_batch = self.encoder(input_tensor, input_lengths)\n",
    "\n",
    "\n",
    "        best_seqs = []\n",
    "        for i in range(len(batch)):\n",
    "            beams = [(torch.tensor([self.special_tokens['<start>']]), 0.0)]  # Start with start token\n",
    "            decoder_hidden = decoder_hidden_batch[:, i, :].unsqueeze(1)  \n",
    "            decoder_target = decoder_target_batch[i].unsqueeze(0)\n",
    "            for j in range(decoder_target.shape[1]-1):\n",
    "                all_candidates = []\n",
    "                for seq, score in beams:\n",
    "                    if seq[-1].item() == self.special_tokens['<end>']:\n",
    "                        all_candidates.append((seq, score))\n",
    "                        continue\n",
    "                    \n",
    "                    \n",
    "                    input_token = seq[-1].unsqueeze(0).unsqueeze(0)  # shape (1,1)\n",
    "                    decoder_output, decoder_hidden = self(decoder_input=input_token, decoder_hidden=decoder_hidden[:,0,:].unsqueeze(1))\n",
    "                    loss += self.loss_fn(decoder_output.squeeze(1), decoder_target[0, j].unsqueeze(0))\n",
    "\n",
    "                    log_probs = torch.log_softmax(decoder_output, dim=-1).squeeze(0).squeeze(0)\n",
    "\n",
    "                    # Get top-k tokens and their log probabilities\n",
    "                    topk_log_probs, topk_tokens = torch.topk(log_probs, self.beam_size)\n",
    "\n",
    "                    for k in range(self.beam_size):\n",
    "                        next_token = topk_tokens[k].unsqueeze(0)\n",
    "                        new_seq = torch.cat([seq, next_token])\n",
    "                        new_score = score + topk_log_probs[k].item()\n",
    "                        all_candidates.append((new_seq, new_score))\n",
    "\n",
    "                # Select top beam_width sequences\n",
    "                beams = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:self.beam_size]\n",
    "\n",
    "                # Optional: break early if all beams ended with end_token\n",
    "                if all(seq[-1].item() == self.special_tokens['<end>'] for seq, _ in beams):\n",
    "                    break\n",
    "\n",
    "            # Return best sequence (highest score)\n",
    "            best_seq = beams[0][0]\n",
    "            best_seqs.append(best_seq)\n",
    "        \n",
    "                # Convert best_seqs to tensor\n",
    "\n",
    "        preds = pad_sequence(best_seqs, batch_first=True, padding_value=self.special_tokens['<pad>'])\n",
    "        print(preds.shape)\n",
    "        #preds = torch.stack(best_seqs)\n",
    "        pred_len = decoder_target_batch.shape[1]\n",
    "        print(best_seqs[0])\n",
    "        accuracy  = 0\n",
    "        #preds = torch.tensor([seq + torch.tensor(self.special_tokens['<pad>'])*(pred_len - len(seq)) for seq in preds])\n",
    "        #print(\"valdation\")\n",
    "        #print(\"preds shape\", preds.shape)\n",
    "        #print(\"decoder target shape\", decoder_target.shape)\n",
    "\n",
    "        #mask = ~torch.isin(decoder_target[:,:-1], torch.tensor(list(self.special_tokens.values())))\n",
    "        #masked_preds = preds[:, :-1].masked_fill(~mask, -1)\n",
    "        #masked_targets = decoder_target[:, :-1].masked_fill(~mask, -1)\n",
    "        #exact_matches = (masked_preds == masked_targets).all(dim=1)\n",
    "        #accuracy = exact_matches.float().mean()\n",
    "    \n",
    "        self.log(\"train loss\", loss, on_step = False, on_epoch = True)\n",
    "        self.log(\"train accuracy\", accuracy, on_step = False, on_epoch = True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_tensor, input_lengths, target_tensor, target_lengths = batch\n",
    "        decoder_input = target_tensor[:, :-1].detach().clone()\n",
    "        decoder_target_batch = target_tensor[:, 1:].detach().clone()\n",
    "        loss = 0\n",
    "        _, decoder_hidden_batch = self.encoder(input_tensor, input_lengths)\n",
    "        \n",
    "\n",
    "        best_seqs = []\n",
    "        for i in range(len(batch)):\n",
    "            beams = [(torch.tensor([self.special_tokens['<start>']]), 0.0)]  # Start with start token\n",
    "            decoder_hidden = decoder_hidden_batch[i].unsqueeze(0)\n",
    "            decoder_target = decoder_target_batch[i].unsqueeze(0)\n",
    "            for j in range(decoder_target.shape[1]-1):\n",
    "                all_candidates = []\n",
    "                for seq, score in beams:\n",
    "                    if seq[-1].item() == self.special_tokens['<end>']:\n",
    "                        all_candidates.append((seq, score))\n",
    "                        continue\n",
    "                    \n",
    "                    \n",
    "                    input_token = seq[-1].unsqueeze(0).unsqueeze(0)  # shape (1,1)\n",
    "                    decoder_output, decoder_hidden = self(decoder_input=input_token, decoder_hidden=decoder_hidden[:,0,:].unsqueeze(1))\n",
    "                    loss += self.loss_fn(decoder_output.squeeze(1), decoder_target[0, j].unsqueeze(0))\n",
    "\n",
    "                    log_probs = torch.log_softmax(decoder_output, dim=-1).squeeze(0).squeeze(0)\n",
    "\n",
    "                    # Get top-k tokens and their log probabilities\n",
    "                    topk_log_probs, topk_tokens = torch.topk(log_probs, self.beam_size)\n",
    "\n",
    "                    for k in range(self.beam_size):\n",
    "                        next_token = topk_tokens[k].unsqueeze(0)\n",
    "                        new_seq = torch.cat([seq, next_token])\n",
    "                        new_score = score + topk_log_probs[k].item()\n",
    "                        all_candidates.append((new_seq, new_score))\n",
    "\n",
    "                # Select top beam_width sequences\n",
    "                beams = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:self.beam_size]\n",
    "\n",
    "                # Optional: break early if all beams ended with end_token\n",
    "                if all(seq[-1].item() == self.special_tokens['<end>'] for seq, _ in beams):\n",
    "                    break\n",
    "\n",
    "            # Return best sequence (highest score)\n",
    "            best_seq = beams[0][0]\n",
    "            best_seqs.append(best_seq)\n",
    "        \n",
    "                # Convert best_seqs to tensor\n",
    "\n",
    "        preds = pad_sequence(best_seqs, batch_first=True, padding_value=self.special_tokens['<pad>'])\n",
    "\n",
    "        #preds = torch.stack(best_seqs)\n",
    "        pred_len = decoder_target_batch.shape[1]\n",
    "        print(preds.shape)\n",
    "        #preds = [seq + torch.tensor(self.special_tokens['<pad>'])*(pred_len - len(seq)) for seq in preds]\n",
    "\n",
    "        mask = ~torch.isin(decoder_target_batch[:,:-1], torch.tensor(list(self.special_tokens.values())))\n",
    "        masked_preds = preds[:, :-1].masked_fill(~mask, -1)\n",
    "        masked_targets = decoder_target_batch[:, :-1].masked_fill(~mask, -1)\n",
    "        exact_matches = (masked_preds == masked_targets).all(dim=1)\n",
    "        accuracy = exact_matches.float().mean()\n",
    " \n",
    "        self.log(\"train loss\", loss, on_step = False, on_epoch = True)\n",
    "        self.log(\"train accuracy\", accuracy, on_step = False, on_epoch = True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        return logits\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.optim == 'sgd':\n",
    "            optimizer = torch.optim.SGD(self.parameters(), lr=self.hparams.lr, momentum=0.9)\n",
    "        elif self.optim == 'adam':\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        return optimizer\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = tokenizer.latin_vocab_size\n",
    "OUTPUT_SIZE = tokenizer.nat_vocab_size\n",
    "EMBEDDING_SIZE = 128\n",
    "HIDDEN_SIZE = 256\n",
    "MAX_TARGET_LEN = 28  # Set this to the maximum length of your target sequences\n",
    "SOS_token = tokenizer.native_vocab['<start>']\n",
    "PAD_TOKEN = tokenizer.native_vocab['<pad>']\n",
    "EOS_token = tokenizer.native_vocab['<end>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | encoder | Encoder          | 365 K  | train\n",
      "1 | decoder | Decoder          | 459 K  | train\n",
      "2 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "824 K     Trainable params\n",
      "0         Non-trainable params\n",
      "824 K     Total params\n",
      "3.299     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]torch.Size([4, 9])\n",
      "tensor([  0, 175, 103,   0, 111,  90,  50,  86, 178])\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 19.83it/s]torch.Size([4, 10])\n",
      "tensor([  0,  10, 155,   1])\n",
      "Epoch 0: 100%|██████████| 2132/2132 [06:36<00:00,  5.37it/s, v_num=qrxt]   torch.Size([4, 5])\n",
      "tensor([  0, 120,  93,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 133, 124, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  15, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  15, 204,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 207,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120,  28,  15, 171,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 133, 124,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  82, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  15, 171,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 221, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 221, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 133, 120,  62,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  28,  15, 207,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 27, 15,  1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0, 216,  28,  15, 204,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0, 216,  28,  15,  93,  84, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 216,  28,  15, 204,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0, 216,  28,  15,  93,  84, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  84, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120,  28,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  15, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  28,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  15,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 216,  28,  15,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 221, 146,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([ 0,  4, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 133, 120, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 133, 124,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120,  62, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  16, 171,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 198, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 19, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  28,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  28,  15, 204,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  27,  15, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  4, 84, 15,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 15, 69, 58,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  19,  84, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 133, 120, 171,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 216,  28,  15, 198, 195,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0,  82, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  36, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  69,  58, 119,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 216,  28,  15,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 29, 28, 15,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82,  28,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 15, 28, 19,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  32,  15, 198, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 15, 69, 62,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 221, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 29,  1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0,  16, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  4, 62, 93, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 207,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 29, 28, 15,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 82, 28, 15,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  82,  28,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 171, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82,  28,  15, 207,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0, 120,  28,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  28,  15, 204,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120,  28,  15, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  32,  15, 198, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82,  28,  15, 207,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 216,  28,  15, 198, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 215,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  15, 204,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  32, 133, 124,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  19,  15, 198, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 216,  28,  15, 198, 195,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0, 216, 171, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  28,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 216, 171,  15, 198, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  82,  15, 207,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  19,  84, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  27,  15, 198, 195,   1])\n",
      "torch.Size([4, 3])\n",
      "tensor([ 0, 29,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82,  28,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  32,  15, 198, 119,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0,  15, 204,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  16,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  15, 171,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120,  28,  15, 207,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 27, 15,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  15, 171,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 198, 119,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120,  28,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 163,  27,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  28,  15, 204,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  15,  28,  15, 198, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 82, 27, 19,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 15, 28, 19,  1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0, 216,  28,  15, 198, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 15, 28, 19,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120,  93,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82, 219, 195, 192,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  4, 82,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  15, 204,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  84, 163,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 200, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  32,  15, 198, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82,  15, 198, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 15, 28, 19,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  27,  15, 207,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 216,  28,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  32,  15, 198, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 19, 27, 19,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  32,  15, 198, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82,  28,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 27, 15,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120,  28,  15, 198, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 27, 15,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  15, 171,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120,  93,  86,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  15, 171,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  84, 195,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([ 0,  4, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 108, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 119,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 207,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  27,  15, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  82,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  15, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  28,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  32,  15, 198, 119,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 221, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  15, 171,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0, 216,  28,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  4, 84, 15,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  93,  84,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  32,  15, 207,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 15, 93,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  28,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  19,  15, 198, 119,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120,  28,  15, 198, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 27, 15,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  32,  15, 198, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  4, 82,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  84, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  84, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  84, 195,   1])\n",
      "torch.Size([4, 3])\n",
      "tensor([0, 5, 1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0,  15, 119,   1])\n",
      "torch.Size([4, 3])\n",
      "tensor([ 0, 15,  1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0,  15, 119,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120,  28,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  15, 171,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120,  93,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 171, 106,  82,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 133, 124,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  28,  15, 171,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 198, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 171, 106,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120,  28,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  28,  15, 207,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  28,  15, 171,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 171,  15,  93,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120,  28,  15, 171,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120,  28,  15, 198, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 171,  15, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 29, 28, 15,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  32,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  32,  15, 198, 119,   1])\n",
      "torch.Size([4, 3])\n",
      "tensor([ 0, 16,  1])\n",
      "Epoch 1: 100%|██████████| 2132/2132 [06:35<00:00,  5.39it/s, v_num=qrxt]torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  27,  15, 200, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([ 0, 94, 62, 93, 86,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 27, 15,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 106,  84,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84, 149, 119,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  82, 183,  16,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 112, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 112,  93,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 155,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 171, 216,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  4, 84, 15,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  19, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4, 112, 192,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  83, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  19, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0, 120, 147, 171,  15, 198, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 171,  15, 198, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 112,  27,  15,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 171,  15, 198, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 28, 15,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  82, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  82, 192,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 90,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 171,  15, 198, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 106,  82,  83,  15,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  28,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  84, 195, 192,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 27, 19,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  82, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  82, 192,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  19, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  83, 171,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 90,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  19, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  84, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  29,  28,  15, 198, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 15, 69, 62,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  81,  58, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 15, 69, 66,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  81,  62, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 82, 28, 15,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 163, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 163,  27,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82,  28,  15, 204,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  19,  17, 119, 172, 107,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  69,  62, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  81,  62, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82,  93,  83, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  81,  62, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  15, 163, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  69,  60, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 15, 69, 66,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 15, 69, 62,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82, 159, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 163,  27,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82, 135,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82, 135,  15,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 15, 69, 62,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  82, 159, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 15, 69, 62,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  81,  62, 146,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([ 0, 82, 93,  1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0,  82, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  29,  28,  15, 171,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  84,  15,  28,  15, 207,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  84,  15,  28,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  69,  62, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 29, 15,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 15, 81, 58,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82,  28,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 29, 28, 15, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  81,  62, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82,  28,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82,  28,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 163,  27,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 19, 93, 86,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  36, 147, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82,  28,  15, 207,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  29,  28,  15, 198, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  69,  58, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  84,  15, 204,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  82, 135, 107,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  15, 163, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  29,  28,  15, 198, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 15, 69, 62,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  15,  69,  62, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 15, 69, 62,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  81,  58, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  29,  28,  15, 204,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  15, 163, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82,  28,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82,  28,  15, 207,   1])\n",
      "torch.Size([4, 3])\n",
      "tensor([ 0, 32,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 15, 81, 62,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82,  28,  15, 146,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0,  15, 163,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  15, 163, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 163, 106,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 171,  15, 200, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 82, 28, 15,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 15, 69, 62,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  15,  81,  58, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  81,  62, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 19, 93, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82,  28,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  81,  58, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  81,  62, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 82, 93, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 29, 93, 86,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  15, 163,  27,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82,  28,  15, 171,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 15, 69, 62,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  84,  15,  28,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 15, 69, 66,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 82, 28, 15,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 82, 28, 15,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  82, 135,  15,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  84, 148,  15, 204,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  27,  17, 172,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  15, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  84, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  84, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 27, 19,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  27,  15, 200, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4, 112,  93,  86, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 149, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 27, 19,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  82, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  82, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 106,  84,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  28,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120,  28,  15, 200, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4, 112,  93,  86, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  82, 192,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 106,  84, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 147,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 106,  84,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([ 0,  6, 42,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120,  93,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 106,  82,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  82, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 83,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  93,  83, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 134,  84,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 106,  82,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 147,  86,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  84, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 106,  82, 107,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 183,  19,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84, 183,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  82, 192,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  84, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  15, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4, 112, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([ 0, 94, 58, 93, 86,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  82, 183,  16,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  82, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  82, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 106,  82,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 149, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  82, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  84, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  28,  15, 198, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4, 142,  93,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6,  15, 207,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  84, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  84, 195,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0, 134,  72,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 186, 147, 119,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0, 185,  27,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0, 186, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  83, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 27, 19,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 112,  60,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 155,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 112,  93,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  19, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 106,  82,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 112,  93,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  93,  86, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120,  28,  15, 200, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 27, 19,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  27,  17, 172,  86,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  27,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 171,  15, 198, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 171,  15, 198, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 163,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 240,  60, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  82, 159, 119,   1])\n",
      "torch.Size([4, 3])\n",
      "tensor([ 0, 15,  1])\n",
      "Epoch 2: 100%|██████████| 2132/2132 [06:36<00:00,  5.38it/s, v_num=qrxt]torch.Size([4, 7])\n",
      "tensor([  0,   4,  84, 163, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142,  27,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142, 148, 107,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 82,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84, 148,  15,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84, 163, 106,  82,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 174, 151, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 90,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 204,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4, 174, 133,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  86, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  83, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  19, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 174, 147,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([ 0,  4, 84, 15, 93, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  28,  15, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142, 148, 107,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84, 148, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 147,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84, 148,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 27, 15, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142, 148,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148,  15,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 183,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 174,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142, 151, 146,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0,   4, 142,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142,  15,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  19, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148, 195,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0,   6,  27,  15, 200,  27,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142, 151, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  4, 84, 15, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 147,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142, 148, 107,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  19, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  83, 171,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 200, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 90,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 183,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142, 148,  15,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 183,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 174, 151, 146,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0,  15, 224,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0,  15, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 171,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 200, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 221, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 207,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  16, 160,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4, 142, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 27, 23,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  15, 204,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84, 163, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84, 148,  15, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142, 148, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148,  15,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 198, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 27, 19,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  19, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 183,  19,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84, 148,  15, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  15, 204,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 133,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([0, 6, 1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  82, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  15, 224,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 174, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  19, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 27, 19,  1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0,   4, 174,  27,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 174, 151, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 82, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84, 163, 106,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4, 112,  15, 198, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  4, 84, 15, 86,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 200, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84, 148,  15,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0,   6,  27,  15, 200,  27,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 174, 151, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  19, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148,  15,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4, 142, 148,  19, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 183,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 174, 147,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148, 107,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 200, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 200, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  4, 84, 15,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 159, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 27, 17,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 90,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4, 142, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  4, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 133,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  83, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  83, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  4, 84, 15,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  15, 224,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 27, 15, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 119,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4, 174,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  4, 84, 15,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142,  27,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 133,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 174, 151, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  4, 84, 15, 86,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84, 163, 106,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84, 148,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 183,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 82,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148,  15,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4, 174,  15, 198, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0,  15, 224,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0,   6, 119,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0, 219,  69,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 147, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 207,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6, 133, 120,  27,  19,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4, 142,  27,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  93,  84, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 148,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 27, 15, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  19, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  27,  19, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0,   6,  27,  15, 200,  27,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 93, 86,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 207,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 93, 82,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6,  93,  84, 119])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 174, 119,   1])\n",
      "torch.Size([4, 3])\n",
      "tensor([  0, 126,   1])\n",
      "Epoch 3: 100%|██████████| 2132/2132 [06:37<00:00,  5.36it/s, v_num=qrxt]torch.Size([4, 6])\n",
      "tensor([  0,   4, 174, 147,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4, 214,  27,  19, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4, 174, 147,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142, 106,  82,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 174, 148,  15,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 27, 17,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  84, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 214, 147,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 214, 151, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  90,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4, 142, 106,  82,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 159,  93,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 159,  93,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 159, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4, 159,  93,  84, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4, 159, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  84, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4,  84,  15, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 214,  15, 204,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4, 214,  27,  15, 207,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   4, 159,  28,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142, 106,  82,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 214,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  4, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 174,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 174, 147,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 210,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 219, 147, 171,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 208, 106,  82,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  60, 147,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 210,  15, 204,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   8, 147,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 159,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 174,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 151, 146,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0,   4, 214,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 214,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  82,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 133, 124,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 214,  15, 207,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  15, 161,  27,  15, 207,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 106,  82, 183,   1])\n",
      "torch.Size([4, 9])\n",
      "tensor([  0,  15,  93,  82, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 147,  90,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 106,  82, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 15, 93, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 161,  27,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  96,  84, 147,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 15, 93, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  96, 176,  93,  86,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  96,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  96,  15, 200, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82,  93,  82, 171,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0, 120, 147, 171,  15, 200, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 147,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 147,  93,  84,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  96,  15, 204,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 147,  86,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 147,  93,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  15, 161,  27,  23,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 147,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 15, 93, 84,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 126, 147,  86,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 147,  93,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  19,  17, 172,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  93,  86, 146,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0,  19, 180,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0, 134, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 161,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0, 120, 147, 133,  59,  19, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 147, 133,  58, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  15,  93,  84, 151, 146,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0, 120, 147,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0, 134,  66,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 147,  93,  84, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  19,  27,  15, 200,  27,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 147, 171,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  96, 192, 149, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 147,  93,  90,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 147,  93,  90,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 147, 133, 120,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 134,  93,  84, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  96, 192, 149, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 106,  82, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  93,  82, 171,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 147, 216,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 15, 93, 82,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 147,  93,  84,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0, 120, 147,  27,  15, 207,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0, 120, 147, 183, 172,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  96, 176,  15, 221, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  96, 114,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 96, 27, 15,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 161,  27,  23,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  96,  15, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  19, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 147,  93,  84, 195,   1])\n",
      "torch.Size([4, 3])\n",
      "tensor([  0, 134,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  96,  27,  15, 207,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  15,  81,  59,  15, 146,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0, 134, 161,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  28,  15, 207,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  96, 176,  17, 172,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  15,  81,  60,  58, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  96,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 106,  84, 221,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  96,  27,  15, 198, 119,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120,  93,  84, 188, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 161,  27,  23,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  96,  15, 200,  58, 119,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 147,  28,  15, 207,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 106,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  96, 114, 172,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  15,  81,  62,  15, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  15, 133, 124,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  96,  84, 163, 106,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  15, 163,  27,  19, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  96,  15, 204,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  96,  15, 215,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 96, 15, 93,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 15, 93, 82,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  96,  84, 147,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 147, 171,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120,  19, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 134,  93,  84, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 147,  93,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 147,  93,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  96, 176,  15, 221, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  96,  84, 147,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  15, 161, 148,  19, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  82, 161, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  19, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120,  19, 207,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 147,  83,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 15, 93, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 126, 147,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 106,  82,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0, 120, 147, 171,  15, 221, 146,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0, 120, 147, 171,  15, 200, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 106,  82,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  96,  15, 198, 119,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  96, 176,  17, 172,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 147,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  19,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 15, 93, 90,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  19,  17, 172,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 135,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 147,  93,  84,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  15, 204,  27,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  96, 114, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 134,  93,  84, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 134,  93,  84, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82, 161,  93,  86,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 134, 192,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  96, 217,  15,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  96, 176,  17, 172,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 134,  93,  84, 119,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([ 0, 82, 93, 82,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 161,  27,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  96, 176, 216,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 147, 160,  15,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  96,  15,  93,  84, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 147, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 204, 151, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  96, 176,  93,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 147, 216,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 147, 133, 120,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 15, 93, 82,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 147,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 221, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 96, 15,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 134,  93,  84, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 134,  84, 119,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  15, 161,  27,  15, 207,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 15, 93, 82,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  82,  93,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 15, 93, 90,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  82, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4, 174, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   4,  84, 195,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([ 0,  4, 82,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  4, 84,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 134, 119,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([ 0, 30, 69,  1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0,  30, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 219, 147, 171,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 208,  27,  19,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 219, 147,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  81,  59,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 210,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 208,  27,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 210,  15, 207,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 224,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 208, 171,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 216, 163,  27,  19, 146,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0, 216, 208,  27,  15, 200, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 216, 210,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 219, 183,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 210, 148,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  81,  62,  93,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  60, 147,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  60,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  60,  15, 207,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 106,  82,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 134,  84, 147, 119])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  96,  15, 198, 119,   1])\n",
      "torch.Size([4, 3])\n",
      "tensor([ 0, 17,  1])\n",
      "Epoch 4: 100%|██████████| 2132/2132 [06:40<00:00,  5.32it/s, v_num=qrxt]torch.Size([4, 7])\n",
      "tensor([  0,   6,  27,  17, 172,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  27,  15, 200, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 174, 147,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84, 148, 107,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142,  27,  19,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 27, 16,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  15, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 133, 124,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 160,  19, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 106,  84,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0,   6,  27,  15, 200, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  90,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  15, 224,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 147, 160,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0,  6, 27, 19,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  27,  15, 200, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6, 147, 171,  15, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  15, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  15, 207,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  27,  15, 200, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 147, 171, 224,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0,   4, 174,  27,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 147, 135, 107,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6, 147,  28,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142, 148,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4,  84,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  15, 204,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 147,  28,  19,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0,  6, 27, 15,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  27,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   4, 142, 133,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6, 106,  83,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  15, 204,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6, 147, 216,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  27,  17, 172,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6,  27,  15, 204,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6, 147,  28,  19, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 147,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([ 0,  6, 27, 19,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6, 147,  28,  15,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,   6, 147, 171,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  11, 183,  19,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,   6,  27,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  82, 186, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  84, 186, 163, 106,  86,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0,  19, 174,  58, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 15, 28, 15, 93,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  36, 119,  15, 146,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0,  19,  84, 195, 192,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  84, 186, 163,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120,  62,  93,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 216, 183, 172,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  69,  58, 107,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  84,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  28,  19, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 147, 107, 171,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0,  15, 133, 120,  62, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  15, 197, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 122,  58,  93,  84, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  84, 167, 155,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  82, 119, 176,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 159, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 15, 69, 66,  1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120,  28,  17,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  19, 135,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 171, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  82, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 171, 106,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 171,  27,  19, 146,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([ 0, 19, 84,  1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0, 134, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 147, 216, 171,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  19,  84,  15, 200, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  15, 163,  27,  19, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  29,  28,  15, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 134,  84,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  84,  15, 204,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  29,  93,  84, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  19, 174, 147,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  94,  15,  28,  15, 207,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  32, 147,  28,  15, 207,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  19,  84, 195, 192,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  84, 155,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  19,  84,  15, 200,  27,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  36, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  29,  93,  84, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 147, 160, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 147, 107, 171,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  36, 183,  16,  15,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 122, 161, 148,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  28,  15, 207,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120,  62,  15, 198, 195,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  19, 174,  27,  19,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  19,  84, 163, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  82, 186, 163, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 163,  58, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  84,  15, 204,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  36, 147, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  19, 208, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  29, 119,  15, 207,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0,  32, 232,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  28,  15, 207,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 147, 146,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([ 0, 19, 84,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  28,  19, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 171, 106,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  32, 147, 135,  19, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 19, 84, 15,  1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  82, 119, 120,  86,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0, 122,  58, 133, 120,  62, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  19,  84, 163, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  84, 186, 163, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 163, 106,  90,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  93,  82, 119,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 122, 159,  93,  84, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 147,  86,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0,  19, 174,  27,  17, 172,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  32,  27,  17, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  84, 186, 163,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 171, 106,  86,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0,  19, 174,  27,  19, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 15, 28, 15,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  19, 208,  15, 204,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  19,  84, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  19, 135,  15,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120,  62,  93,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  84, 186, 163, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  19,  84,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  19, 208,  93,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  19,  84,  15, 198, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120, 147,  28,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  36,  27,  15, 200, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  36, 183, 172,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  19, 174, 147,  86, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  19, 174, 147, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 171,  27,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  36, 119,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  28,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  36, 119, 142,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  19, 174, 147,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 171, 106,  86,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  36, 119, 120,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  84,  15, 200, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  19, 174,  27,  19, 146,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 120,  82, 116,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 163,  27,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 147,  28,  19,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 147,  86,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  19, 174,  27,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  36, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 171, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120,  82,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  15, 163, 207,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  29, 159, 236,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  19, 174, 108, 171,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  15, 197, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  69,  58, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 171, 106,  86,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  29, 161,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  36, 147, 135,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  84, 147,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  19,  84, 147, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([ 0, 15, 69, 58,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 171, 106,  86,   1])\n",
      "torch.Size([4, 8])\n",
      "tensor([  0, 135, 161,  27,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  29, 119, 172,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  19,  84,  15, 207,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  29,  15, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 147, 221, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 135, 161,  27,  19,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 122, 133, 120,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 120, 147, 216,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([ 0, 84, 54, 93,  1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 120, 171, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15,  93,  84, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  29, 135,  15,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  15,  28,  15, 198, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  15, 159, 119,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0,  19, 174, 147, 195,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  36, 183,  16,  15,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  15, 216, 161, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  19,  84, 195, 192,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   5, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   5, 119,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   6, 106,  84, 195,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0,   6, 147,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,   5, 159,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0,  29, 119,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0, 194,  69,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 186, 147, 119,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 210,  15, 207,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 163,  27,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 208, 106,  86,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 216, 208,  27,  16,   1])\n",
      "torch.Size([4, 4])\n",
      "tensor([  0, 216,  23,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 208,  27,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 106,  82, 195,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 216,  23, 147,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216,  23,  27,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 210, 151, 146,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 216,  23,  15, 200, 146,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 208,  27,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 208,  27,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 208, 106,  86,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 208,  27,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 208,  27,  19,   1])\n",
      "torch.Size([4, 7])\n",
      "tensor([  0, 216, 208,  27,  19,   1])\n",
      "torch.Size([4, 6])\n",
      "tensor([  0, 216, 208,  27,  19,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0,  19,  84, 148,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 122, 159, 119,   1])\n",
      "torch.Size([4, 5])\n",
      "tensor([  0, 122, 159, 119,   1])\n",
      "torch.Size([4, 3])\n",
      "tensor([  0, 131,   1])\n",
      "Epoch 4: 100%|██████████| 2132/2132 [06:45<00:00,  5.26it/s, v_num=qrxt]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2132/2132 [06:45<00:00,  5.26it/s, v_num=qrxt]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                         \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                          \t|  -              \t|  398991         \t|  2011.0         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                             \t|  402.14         \t|  5              \t|  2010.7         \t|  99.984         \t|\n",
      "|  run_training_batch                                                                                                                                             \t|  0.18402        \t|  10660          \t|  1961.6         \t|  97.544         \t|\n",
      "|  [LightningModule]RNN_light.optimizer_step                                                                                                                      \t|  0.18371        \t|  10660          \t|  1958.4         \t|  97.383         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                        \t|  0.16462        \t|  10660          \t|  1754.9         \t|  87.263         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                   \t|  0.017029       \t|  10660          \t|  181.53         \t|  9.0266         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.validation_step                                                                                                                 \t|  0.019485       \t|  1072           \t|  20.888         \t|  1.0387         \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                   \t|  0.0010987      \t|  10660          \t|  11.713         \t|  0.58242        \t|\n",
      "|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                     \t|  0.00084113     \t|  10660          \t|  8.9664         \t|  0.44586        \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_end                                                                                                              \t|  0.0012447      \t|  1072           \t|  1.3343         \t|  0.066351       \t|\n",
      "|  [_EvaluationLoop].val_next                                                                                                                                     \t|  0.0010585      \t|  1072           \t|  1.1347         \t|  0.056422       \t|\n",
      "|  [LightningModule]RNN_light.optimizer_zero_grad                                                                                                                 \t|  8.5173e-05     \t|  10660          \t|  0.90794        \t|  0.045148       \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                 \t|  5.5457e-05     \t|  11732          \t|  0.65062        \t|  0.032353       \t|\n",
      "|  [LightningModule]RNN_light.transfer_batch_to_device                                                                                                            \t|  3.8922e-05     \t|  11732          \t|  0.45664        \t|  0.022707       \t|\n",
      "|  [LightningModule]RNN_light.configure_gradient_clipping                                                                                                         \t|  1.753e-05      \t|  10660          \t|  0.18687        \t|  0.0092925      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end       \t|  0.033345       \t|  5              \t|  0.16672        \t|  0.0082905      \t|\n",
      "|  save_checkpoint                                                                                                                                                \t|  0.031993       \t|  5              \t|  0.15997        \t|  0.0079545      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end       \t|  1.3681e-05     \t|  10660          \t|  0.14584        \t|  0.0072521      \t|\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                    \t|  2.3154e-06     \t|  10660          \t|  0.024682       \t|  0.0012273      \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                      \t|  2.2008e-06     \t|  10660          \t|  0.023461       \t|  0.0011666      \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_start                                                                                                                  \t|  0.0034174      \t|  6              \t|  0.020504       \t|  0.0010196      \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                  \t|  1.3032e-06     \t|  10660          \t|  0.013892       \t|  0.00069082     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                   \t|  1.264e-06      \t|  10660          \t|  0.013474       \t|  0.00067002     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_start                                                                                                            \t|  1.1208e-05     \t|  1072           \t|  0.012015       \t|  0.00059748     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_end                                                                                                                    \t|  0.001794       \t|  6              \t|  0.010764       \t|  0.00053525     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward        \t|  1.0093e-06     \t|  10660          \t|  0.010759       \t|  0.00053499     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                 \t|  1.0004e-06     \t|  10660          \t|  0.010664       \t|  0.00053028     \t|\n",
      "|  [LightningModule]RNN_light.on_before_batch_transfer                                                                                                            \t|  8.7465e-07     \t|  11732          \t|  0.010261       \t|  0.00051026     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                             \t|  7.6983e-07     \t|  10660          \t|  0.0082063      \t|  0.00040807     \t|\n",
      "|  [LightningModule]RNN_light.on_train_batch_end                                                                                                                  \t|  7.3951e-07     \t|  10660          \t|  0.0078831      \t|  0.000392       \t|\n",
      "|  [LightningModule]RNN_light.on_after_backward                                                                                                                   \t|  6.653e-07      \t|  10660          \t|  0.0070921      \t|  0.00035266     \t|\n",
      "|  [LightningModule]RNN_light.on_before_zero_grad                                                                                                                 \t|  6.2152e-07     \t|  10660          \t|  0.0066254      \t|  0.00032945     \t|\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                     \t|  6.1083e-07     \t|  10660          \t|  0.0065115      \t|  0.00032379     \t|\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                       \t|  5.9834e-07     \t|  10660          \t|  0.0063783      \t|  0.00031717     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                            \t|  5.8753e-07     \t|  10660          \t|  0.0062631      \t|  0.00031144     \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                    \t|  5.7044e-07     \t|  10660          \t|  0.0060808      \t|  0.00030238     \t|\n",
      "|  [LightningModule]RNN_light.on_train_batch_start                                                                                                                \t|  5.5732e-07     \t|  10660          \t|  0.005941       \t|  0.00029542     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start     \t|  5.5574e-07     \t|  10660          \t|  0.0059242      \t|  0.00029459     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad      \t|  5.2089e-07     \t|  10660          \t|  0.0055527      \t|  0.00027611     \t|\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                      \t|  5.1902e-07     \t|  10660          \t|  0.0055328      \t|  0.00027512     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward       \t|  5.0596e-07     \t|  10660          \t|  0.0053936      \t|  0.0002682      \t|\n",
      "|  [LightningModule]RNN_light.on_after_batch_transfer                                                                                                             \t|  4.5399e-07     \t|  11732          \t|  0.0053262      \t|  0.00026485     \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                                \t|  4.8194e-07     \t|  10660          \t|  0.0051375      \t|  0.00025547     \t|\n",
      "|  [LightningModule]RNN_light.on_before_backward                                                                                                                  \t|  4.7902e-07     \t|  10660          \t|  0.0051064      \t|  0.00025392     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step \t|  4.6891e-07     \t|  10660          \t|  0.0049986      \t|  0.00024856     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                 \t|  0.00087661     \t|  5              \t|  0.004383       \t|  0.00021795     \t|\n",
      "|  [LightningModule]RNN_light.on_before_optimizer_step                                                                                                            \t|  3.804e-07      \t|  10660          \t|  0.004055       \t|  0.00020164     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                   \t|  0.00057058     \t|  5              \t|  0.0028529      \t|  0.00014186     \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_end                                                                                                                 \t|  2.2972e-06     \t|  1072           \t|  0.0024626      \t|  0.00012245     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                       \t|  0.0022904      \t|  1              \t|  0.0022904      \t|  0.00011389     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_end  \t|  9.2609e-07     \t|  1072           \t|  0.00099277     \t|  4.9367e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_start                                                                                                               \t|  9.1199e-07     \t|  1072           \t|  0.00097765     \t|  4.8615e-05     \t|\n",
      "|  [LightningModule]RNN_light.on_validation_batch_end                                                                                                             \t|  8.2434e-07     \t|  1072           \t|  0.00088369     \t|  4.3942e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_start\t|  7.3993e-07     \t|  1072           \t|  0.0007932      \t|  3.9443e-05     \t|\n",
      "|  [LightningModule]RNN_light.on_validation_batch_start                                                                                                           \t|  6.9582e-07     \t|  1072           \t|  0.00074592     \t|  3.7092e-05     \t|\n",
      "|  [LightningModule]RNN_light.on_validation_model_eval                                                                                                            \t|  0.00010687     \t|  6              \t|  0.00064121     \t|  3.1885e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_start                                                                                                                \t|  0.00062055     \t|  1              \t|  0.00062055     \t|  3.0857e-05     \t|\n",
      "|  [LightningModule]RNN_light.on_validation_model_zero_grad                                                                                                       \t|  0.00011184     \t|  5              \t|  0.00055922     \t|  2.7808e-05     \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                            \t|  0.00054772     \t|  1              \t|  0.00054772     \t|  2.7236e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                         \t|  0.00039016     \t|  1              \t|  0.00039016     \t|  1.9401e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_end        \t|  5.7888e-05     \t|  6              \t|  0.00034733     \t|  1.7271e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                    \t|  7.571e-05      \t|  1              \t|  7.571e-05      \t|  3.7648e-06     \t|\n",
      "|  [LightningModule]RNN_light.configure_optimizers                                                                                                                \t|  7.3426e-05     \t|  1              \t|  7.3426e-05     \t|  3.6512e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                   \t|  4.3541e-06     \t|  5              \t|  2.177e-05      \t|  1.0826e-06     \t|\n",
      "|  [Callback]ModelSummary.on_validation_start                                                                                                                     \t|  3.4398e-06     \t|  6              \t|  2.0639e-05     \t|  1.0263e-06     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                    \t|  3.095e-06      \t|  5              \t|  1.5475e-05     \t|  7.695e-07      \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_start                                                                                                            \t|  2.5775e-06     \t|  6              \t|  1.5465e-05     \t|  7.6901e-07     \t|\n",
      "|  [Callback]ModelSummary.on_validation_end                                                                                                                       \t|  2.0033e-06     \t|  6              \t|  1.202e-05      \t|  5.977e-07      \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_start                                                                                                             \t|  1.8534e-06     \t|  6              \t|  1.112e-05      \t|  5.5297e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start           \t|  1.0882e-05     \t|  1              \t|  1.0882e-05     \t|  5.4112e-07     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                      \t|  1.729e-06      \t|  5              \t|  8.645e-06      \t|  4.2988e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_end                                                                                                              \t|  1.2785e-06     \t|  6              \t|  7.6711e-06     \t|  3.8145e-07     \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                      \t|  1.239e-06      \t|  5              \t|  6.1949e-06     \t|  3.0805e-07     \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                          \t|  6.058e-06      \t|  1              \t|  6.058e-06      \t|  3.0124e-07     \t|\n",
      "|  [LightningModule]RNN_light.on_validation_end                                                                                                                   \t|  7.8313e-07     \t|  6              \t|  4.6988e-06     \t|  2.3365e-07     \t|\n",
      "|  [LightningModule]RNN_light.on_validation_start                                                                                                                 \t|  7.5022e-07     \t|  6              \t|  4.5013e-06     \t|  2.2383e-07     \t|\n",
      "|  [LightningModule]RNN_light.on_validation_epoch_end                                                                                                             \t|  7.0975e-07     \t|  6              \t|  4.2585e-06     \t|  2.1176e-07     \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_end                                                                                                                 \t|  6.4513e-07     \t|  6              \t|  3.8708e-06     \t|  1.9248e-07     \t|\n",
      "|  [LightningModule]RNN_light.on_train_start                                                                                                                      \t|  3.7402e-06     \t|  1              \t|  3.7402e-06     \t|  1.8599e-07     \t|\n",
      "|  [LightningModule]RNN_light.on_train_epoch_end                                                                                                                  \t|  7.4184e-07     \t|  5              \t|  3.7092e-06     \t|  1.8445e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint       \t|  7.3919e-07     \t|  5              \t|  3.696e-06      \t|  1.8379e-07     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_end                                                                                                               \t|  6.0078e-07     \t|  6              \t|  3.6047e-06     \t|  1.7925e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_start      \t|  5.8305e-07     \t|  6              \t|  3.4983e-06     \t|  1.7396e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_end  \t|  5.7684e-07     \t|  6              \t|  3.461e-06      \t|  1.721e-07      \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                  \t|  3.41e-06       \t|  1              \t|  3.41e-06       \t|  1.6957e-07     \t|\n",
      "|  [LightningModule]RNN_light.on_validation_epoch_start                                                                                                           \t|  5.5169e-07     \t|  6              \t|  3.3102e-06     \t|  1.646e-07      \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_start                                                                                                               \t|  5.4917e-07     \t|  6              \t|  3.295e-06      \t|  1.6385e-07     \t|\n",
      "|  [LightningModule]RNN_light.on_train_epoch_start                                                                                                                \t|  6.2436e-07     \t|  5              \t|  3.1218e-06     \t|  1.5523e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start     \t|  6.2161e-07     \t|  5              \t|  3.1081e-06     \t|  1.5455e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                                \t|  2.949e-06      \t|  1              \t|  2.949e-06      \t|  1.4664e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_start\t|  4.8499e-07     \t|  6              \t|  2.9099e-06     \t|  1.447e-07      \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_end                                                                                                                  \t|  2.804e-06      \t|  1              \t|  2.804e-06      \t|  1.3943e-07     \t|\n",
      "|  [LightningModule]RNN_light.on_save_checkpoint                                                                                                                  \t|  5.4683e-07     \t|  5              \t|  2.7341e-06     \t|  1.3596e-07     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_start                                                                                                                   \t|  2.251e-06      \t|  1              \t|  2.251e-06      \t|  1.1193e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                           \t|  1.6522e-06     \t|  1              \t|  1.6522e-06     \t|  8.2156e-08     \t|\n",
      "|  [LightningModule]RNN_light.configure_callbacks                                                                                                                 \t|  1.55e-06       \t|  1              \t|  1.55e-06       \t|  7.7073e-08     \t|\n",
      "|  [LightningModule]RNN_light.on_fit_start                                                                                                                        \t|  1.522e-06      \t|  1              \t|  1.522e-06      \t|  7.5684e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start             \t|  1.366e-06      \t|  1              \t|  1.366e-06      \t|  6.7927e-08     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                         \t|  1.3069e-06     \t|  1              \t|  1.3069e-06     \t|  6.4986e-08     \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                            \t|  1.1879e-06     \t|  1              \t|  1.1879e-06     \t|  5.907e-08      \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                             \t|  1.17e-06       \t|  1              \t|  1.17e-06       \t|  5.8178e-08     \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                   \t|  8.51e-07       \t|  1              \t|  8.51e-07       \t|  4.2317e-08     \t|\n",
      "|  [LightningModule]RNN_light.on_train_end                                                                                                                        \t|  8.3097e-07     \t|  1              \t|  8.3097e-07     \t|  4.1321e-08     \t|\n",
      "|  [LightningModule]RNN_light.setup                                                                                                                               \t|  8.2119e-07     \t|  1              \t|  8.2119e-07     \t|  4.0835e-08     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_end                                                                                                                     \t|  7.3714e-07     \t|  1              \t|  7.3714e-07     \t|  3.6655e-08     \t|\n",
      "|  [LightningModule]RNN_light.teardown                                                                                                                            \t|  6.6985e-07     \t|  1              \t|  6.6985e-07     \t|  3.3309e-08     \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                                \t|  5.9418e-07     \t|  1              \t|  5.9418e-07     \t|  2.9546e-08     \t|\n",
      "|  [LightningModule]RNN_light.on_fit_end                                                                                                                          \t|  5.851e-07      \t|  1              \t|  5.851e-07      \t|  2.9095e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end             \t|  5.4413e-07     \t|  1              \t|  5.4413e-07     \t|  2.7057e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                 \t|  5.39e-07       \t|  1              \t|  5.39e-07       \t|  2.6803e-08     \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                              \t|  5.2201e-07     \t|  1              \t|  5.2201e-07     \t|  2.5957e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_end      \t|  4.8894e-07     \t|  1              \t|  4.8894e-07     \t|  2.4313e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_start    \t|  4.8219e-07     \t|  1              \t|  4.8219e-07     \t|  2.3978e-08     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                    \t|  4.3004e-07     \t|  1              \t|  4.3004e-07     \t|  2.1384e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end               \t|  4.1095e-07     \t|  1              \t|  4.1095e-07     \t|  2.0435e-08     \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m trainer = pl.Trainer(max_epochs=\u001b[32m5\u001b[39m,  accelerator=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,logger=logger, profiler=\u001b[33m'\u001b[39m\u001b[33msimple\u001b[39m\u001b[33m'\u001b[39m,  precision=\u001b[33m\"\u001b[39m\u001b[33m16-mixed\u001b[39m\u001b[33m\"\u001b[39m,)\n\u001b[32m     21\u001b[39m trainer.fit(model, train_dataloader,  valid_dataloader)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m#trainer.save_checkpoint(\"trained_model.ckpt\")\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/conda/miniconda3/envs/dla3/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:775\u001b[39m, in \u001b[36mTrainer.test\u001b[39m\u001b[34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28mself\u001b[39m.state.status = TrainerStatus.RUNNING\n\u001b[32m    774\u001b[39m \u001b[38;5;28mself\u001b[39m.testing = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m775\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_test_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/conda/miniconda3/envs/dla3/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     51\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/conda/miniconda3/envs/dla3/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:817\u001b[39m, in \u001b[36mTrainer._test_impl\u001b[39m\u001b[34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[39m\n\u001b[32m    813\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    814\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    815\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn, ckpt_path, model_provided=model_provided, model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    816\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m817\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[38;5;66;03m# remove the tensors from the test results\u001b[39;00m\n\u001b[32m    819\u001b[39m results = convert_tensors_to_scalars(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/conda/miniconda3/envs/dla3/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.register_signal_handlers()\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1017\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: trainer tearing down\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/conda/miniconda3/envs/dla3/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1049\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1046\u001b[39m \u001b[38;5;28mself\u001b[39m.lightning_module.zero_grad()\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluating:\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluation_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predicting:\n\u001b[32m   1051\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predict_loop.run()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/conda/miniconda3/envs/dla3/lib/python3.11/site-packages/lightning/pytorch/loops/utilities.py:179\u001b[39m, in \u001b[36m_no_grad_context.<locals>._decorator\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    177\u001b[39m     context_manager = torch.no_grad\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/conda/miniconda3/envs/dla3/lib/python3.11/site-packages/lightning/pytorch/loops/evaluation_loop.py:145\u001b[39m, in \u001b[36m_EvaluationLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28mself\u001b[39m.batch_progress.is_last_batch = data_fetcher.done\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    147\u001b[39m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/conda/miniconda3/envs/dla3/lib/python3.11/site-packages/lightning/pytorch/loops/evaluation_loop.py:437\u001b[39m, in \u001b[36m_EvaluationLoop._evaluation_step\u001b[39m\u001b[34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[39m\n\u001b[32m    431\u001b[39m hook_name = \u001b[33m\"\u001b[39m\u001b[33mtest_step\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.testing \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvalidation_step\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    432\u001b[39m step_args = (\n\u001b[32m    433\u001b[39m     \u001b[38;5;28mself\u001b[39m._build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[32m    434\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[32m    436\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m output = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[38;5;28mself\u001b[39m.batch_progress.increment_processed()\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[32m    442\u001b[39m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/conda/miniconda3/envs/dla3/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:328\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[32m    331\u001b[39m pl_module._current_fx_name = prev_fx_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/conda/miniconda3/envs/dla3/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:425\u001b[39m, in \u001b[36mStrategy.test_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    423\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model != \u001b[38;5;28mself\u001b[39m.lightning_module:\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_redirection(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.lightning_module, \u001b[33m\"\u001b[39m\u001b[33mtest_step\u001b[39m\u001b[33m\"\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtest_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 144\u001b[39m, in \u001b[36mRNN_light.test_step\u001b[39m\u001b[34m(self, batch, batch_idx)\u001b[39m\n\u001b[32m    140\u001b[39m _, decoder_hidden_batch = \u001b[38;5;28mself\u001b[39m.encoder(input_tensor, input_lengths)\n\u001b[32m    143\u001b[39m best_seqs = []\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    145\u001b[39m     beams = [(torch.tensor([\u001b[38;5;28mself\u001b[39m.special_tokens[\u001b[33m'\u001b[39m\u001b[33m<start>\u001b[39m\u001b[33m'\u001b[39m]]), \u001b[32m0.0\u001b[39m)]  \u001b[38;5;66;03m# Start with start token\u001b[39;00m\n\u001b[32m    146\u001b[39m     decoder_hidden = decoder_hidden_batch[i].unsqueeze(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'tuple' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "os.environ['WANDB_API_KEY'] = \"761e2f0f9986fd2e6ee9f21ef44a2665e0bc8618\"\n",
    "wandb.login(key=os.getenv(\"WANDB_API_KEY\"))\n",
    "special_tokens = {key: val for key, val in tokenizer.native_vocab.items() if key in ['<start>', '<end>', '<pad>']}\n",
    "\n",
    "model = RNN_light(\n",
    "    input_sizes=(tokenizer.latin_vocab_size, tokenizer.nat_vocab_size),\n",
    "    embedding_size=EMBEDDING_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    cell='rnn',\n",
    "    layers=3,\n",
    "    dropout=0.1,\n",
    "    activation='tanh',\n",
    "    beam_size=3,\n",
    "    optim='adam',\n",
    "    special_tokens=special_tokens,\n",
    "    lr=0.001\n",
    "    \n",
    ")\n",
    "logger= WandbLogger(project= 'rnntest', name = \"test\",resume=\"never\")\n",
    "trainer = pl.Trainer(max_epochs=5,  accelerator=\"auto\",logger=logger, profiler='simple',  precision=\"16-mixed\",)\n",
    "trainer.fit(model, train_dataloader,  valid_dataloader)\n",
    "trainer.test(model, dataloaders=test_dataloader)\n",
    "#trainer.save_checkpoint(\"trained_model.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dla3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
